{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Ising model from scratch:\n",
    "In this notebook, Markov Chain Monte Carlo sampling is used to sample configurations of Ising model for T=1 to T=3. Full-connected Neural Network(FCNN) is applied to learn the classifier of paramagnetism and ferromagnetism phases. The FCNN is done from scratch and later by TensorFlow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Ising model\n",
    "$H=-J\\sum_{<i,j>}S_{i}S_{j}$\n",
    "The \"data\" of the ML problem corresponds to configuration of Ising model.\n",
    "That is, $\\vec{x}=(s_{1},s_{2},...,s_{N})$ where $s_{i}= 1, -1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We label our Ising model data by its phase. For $T<T_{C}$ we label this ferromagnetic phase $y=1$ and $T>T_{C}$ for paramagnetic phase,  $y=0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll generate those datas from some distribution by Monte Carlo method. The distribution behind the data is Boltzmann distribution $P_{\\mu}=\\frac{1}{Z}e^{-\\beta E_{\\mu}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use MCMC to sample states by updating the current state $\\mu$ to next one $\\nu$. In principle, any rule of updating is possible. For example, given state $\\vec{x}_{\\mu}=(1,-1,-1,1,1)$, we can propose next one $\\vec{x}_{\\nu}$ by\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1)Single spin flip: $\\vec{x}_{\\nu}=(-1,-1,-1,1,1)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2)Non-local spin flip (cluster algorithm): $\\vec{x}_{\\nu}=(-1,1,1,-1,-1)$   (Just for specific example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we should restrict the rule of updating due to the $P_{\\mu}$ from which we hope our sampling won't be too irrelevant, the so-called importance sampling. We should encode the underlying Boltzmann distribution to our sampling rule which we denote by $T(\\mu \\rightarrow\\nu)$. Computationally we can write this T by $T(\\mu\\rightarrow\\nu)=g(\\mu\\rightarrow\\nu)A(\\mu\\rightarrow\\nu)$, where $g(\\mu\\rightarrow\\nu)$ is proposal rate and $A(\\mu\\rightarrow\\nu)$ is acceptance rate. The transition probability $T(\\mu \\rightarrow\\nu)$ satisfies the following two quite general conditions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Normalized transition probability: $\\sum_{\\nu}T(\\mu\\rightarrow\\nu)=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Detailed balance: $P_{\\nu}T(\\nu\\rightarrow\\mu)=P_{\\mu}T(\\mu\\rightarrow\\nu)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $P_{\\mu}$ is Boltzmann distribution, apply detailed balance then we have $\\frac{T(\\mu->\\nu)}{T(\\nu->\\mu)}=e^{-\\beta(E_{\\nu}-E_{\\mu})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write by proposal and acceptance rate, we have $\\frac{A(\\mu\\rightarrow\\nu)}{A(\\nu\\rightarrow\\mu)}=\\frac{g(\\nu\\rightarrow\\mu)}{g(\\mu\\rightarrow\\nu)}e^{-\\beta(E_{\\nu}-E_{\\mu})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any Monte Carlo algorithm with g and A satisfying this equation can do the job. One of them is the famous Metropolis Algorithm: $A(\\mu\\rightarrow\\nu)=\\text{min}(1,\\frac{g(\\nu\\rightarrow\\mu)}{g(\\mu\\rightarrow\\nu)}e^{-\\beta(E_{\\nu}-E_{\\mu})})$. This way of encoding underlying distribution can optimizes the acceptance rate under the consideration of importance sampling. That is, proposal of the highly probable states should be highly accepted. The higher the acceptance rate for important states the more efficient the sampling is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications of Monte Carlo in Machine Learning (To be completed...)\n",
    "MCMC sampling can be used in many ML algorithm in the future, here we list some yet many more items are to be included"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Sampling states.\n",
    "(2) Approximate the gradient in RBM. \n",
    "(3)...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo code of MCMC sampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "choose an initial state $\\mu_{1}$ randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i = 2 ~ N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use $g(\\mu_{i-1}\\rightarrow\\nu)$ to propose an update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate a number r uniformly randomly from [0,1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare this random number r with A($\\mu_{1}\\rightarrow\\nu$) which is from Metropolis algorithm : \n",
    "if r< A($\\mu_{1}\\rightarrow\\nu$)  then accept this new state by assigning $\\mu_{i}=\\nu$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "else $\\mu_{i}=\\mu_{i-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import boltzmann as bzm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use MCMC to sample states and calculate the average energy of the whole system at some temperature T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean energy per spin: -1.7392933333333334 Number of acceptance 2537 acceptance rate: 0.08456666666666666\n"
     ]
    }
   ],
   "source": [
    "# Define energy function to calculate energy according to Ising Hamiltonian\n",
    "def energy(state, N, nbr):\n",
    "    E = 0.0\n",
    "    for k in range(N):\n",
    "        E -=  state[k] * sum(state[nn] for nn in nbr[k])\n",
    "    return 0.5 * E\n",
    "\n",
    "# Define the lattice by neighbors of each site. (with periodic b.c.)\n",
    "L = 10\n",
    "N = L * L\n",
    "nbr = {i : ((i // L) * L + (i + 1) % L, (i + L) % N,\n",
    "            (i // L) * L + (i - 1) % L, (i - L) % N) \\\n",
    "                                    for i in range(N)}\n",
    "\n",
    "T = 2.0                                                             # Temperature\n",
    "state = [random.choice([1, -1]) for k in range(N)]                  # Generate an initial state randomly\n",
    "nsteps = N * 300                                                    # Number of proposals\n",
    "Energy = energy(state, N, nbr)                                      # Energy of the whole lattice initially\n",
    "E = np.zeros(nsteps)                                                # To record energies of sampled states\n",
    "States = np.zeros((nsteps,N))                                           # To record sampled states\n",
    "accept = 0                                                          # To Count the number of acceptance\n",
    "for step in range(nsteps):                                          # Going to propose nstep move to flip spin\n",
    "    k = random.randint(0, N - 1)                                    # Randomly pick a spin among the N sites   \n",
    "    delta_E = 2.0 * state[k] * sum(state[nn] for nn in nbr[k])      # Calculate the energy change due to this flip. \n",
    "    if random.uniform(0.0, 1.0) < math.exp(-1.0 / T * delta_E):     # The condition for acceptance (Think about the condition)\n",
    "        accept += 1\n",
    "        state[k] *= -1                                              # Satisfy the condition, flip this spin\n",
    "        Energy += delta_E                                           # Fulfill the energy change\n",
    "    States[step] = np.array(state)                                  # Record this new state\n",
    "    E[step] = Energy                                                # Record the energy of this step\n",
    "    \n",
    "print('mean energy per spin:', sum(E) / float(len(E) * N),'Number of acceptance', accept, 'acceptance rate:', accept/nsteps)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we sample more states for different temperatures T, we note that in the present T=2 case, the states we sample are indeed the relevant ones as shown in the histogram graph below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.763e+03, 6.968e+03, 5.195e+03, 6.570e+03, 2.454e+03, 7.750e+02,\n",
       "        6.940e+02, 1.150e+02, 5.400e+01, 9.400e+01, 1.580e+02, 7.300e+01,\n",
       "        2.300e+01, 1.400e+01, 7.000e+00, 7.000e+00, 3.000e+00, 8.000e+00,\n",
       "        2.200e+01, 3.000e+00]),\n",
       " array([-2.   , -1.894, -1.788, -1.682, -1.576, -1.47 , -1.364, -1.258,\n",
       "        -1.152, -1.046, -0.94 , -0.834, -0.728, -0.622, -0.516, -0.41 ,\n",
       "        -0.304, -0.198, -0.092,  0.014,  0.12 ]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(E/N,bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start sampling\n",
    "First, define the system size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the lattice by neighbors of each site. (with periodic b.c.)\n",
    "L = 10\n",
    "N = L * L\n",
    "nbr = {i : ((i // L) * L + (i + 1) % L, (i + L) % N,\n",
    "            (i // L) * L + (i - 1) % L, (i - L) % N) \\\n",
    "                                    for i in range(N)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sample for different T, we divide the temperature interval from T=1 to T=3 into pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.  , 1.01, 1.02, 1.03, 1.04, 1.05, 1.06, 1.07, 1.08, 1.09, 1.1 ,\n",
       "       1.11, 1.12, 1.13, 1.14, 1.15, 1.16, 1.17, 1.18, 1.19, 1.2 , 1.21,\n",
       "       1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3 , 1.31, 1.32,\n",
       "       1.33, 1.34, 1.35, 1.36, 1.37, 1.38, 1.39, 1.4 , 1.41, 1.42, 1.43,\n",
       "       1.44, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5 , 1.51, 1.52, 1.53, 1.54,\n",
       "       1.55, 1.56, 1.57, 1.58, 1.59, 1.6 , 1.61, 1.62, 1.63, 1.64, 1.65,\n",
       "       1.66, 1.67, 1.68, 1.69, 1.7 , 1.71, 1.72, 1.73, 1.74, 1.75, 1.76,\n",
       "       1.77, 1.78, 1.79, 1.8 , 1.81, 1.82, 1.83, 1.84, 1.85, 1.86, 1.87,\n",
       "       1.88, 1.89, 1.9 , 1.91, 1.92, 1.93, 1.94, 1.95, 1.96, 1.97, 1.98,\n",
       "       1.99, 2.  , 2.01, 2.02, 2.03, 2.04, 2.05, 2.06, 2.07, 2.08, 2.09,\n",
       "       2.1 , 2.11, 2.12, 2.13, 2.14, 2.15, 2.16, 2.17, 2.18, 2.19, 2.2 ,\n",
       "       2.21, 2.22, 2.23, 2.24, 2.25, 2.26, 2.27, 2.28, 2.29, 2.3 , 2.31,\n",
       "       2.32, 2.33, 2.34, 2.35, 2.36, 2.37, 2.38, 2.39, 2.4 , 2.41, 2.42,\n",
       "       2.43, 2.44, 2.45, 2.46, 2.47, 2.48, 2.49, 2.5 , 2.51, 2.52, 2.53,\n",
       "       2.54, 2.55, 2.56, 2.57, 2.58, 2.59, 2.6 , 2.61, 2.62, 2.63, 2.64,\n",
       "       2.65, 2.66, 2.67, 2.68, 2.69, 2.7 , 2.71, 2.72, 2.73, 2.74, 2.75,\n",
       "       2.76, 2.77, 2.78, 2.79, 2.8 , 2.81, 2.82, 2.83, 2.84, 2.85, 2.86,\n",
       "       2.87, 2.88, 2.89, 2.9 , 2.91, 2.92, 2.93, 2.94, 2.95, 2.96, 2.97,\n",
       "       2.98, 2.99])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = np.zeros(200)                                              # Set up temperature series\n",
    "T[0] = 1\n",
    "for delta in range(199): \n",
    "    T[delta+1] = T[delta]+0.01\n",
    "T    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps = N * 100                                                        # Number of proposals\n",
    "S = np.zeros((len(T),nsteps,N))                                         # To record sampled states\n",
    "E = np.zeros((len(T), nsteps))                                          # To record energies of sampled states\n",
    "state = [random.choice([1, -1]) for k in range(N)]                      # Generate an initial state randomly\n",
    "Energy = energy(state, N, nbr)                                          # Energy of the whole lattice initially\n",
    "\n",
    "for t in range(len(T)):                                                 # iterate all temperatures\n",
    "    for step in range(nsteps):                                          # Going to propose nstep move to flip spin\n",
    "        k = random.randint(0, N - 1)                                    # Randomly pick a spin among the N sites   \n",
    "        delta_E = 2.0 * state[k] * sum(state[nn] for nn in nbr[k])      # Calculate the energy change due to this flip. \n",
    "        if random.uniform(0.0, 1.0) < math.exp(-1.0 / T[t] * delta_E):     # The condition for acceptance (Think about the condition)\n",
    "            state[k] *= -1                                              # Satisfy the condition, flip this spin\n",
    "            Energy += delta_E                                           # Fulfill the energy change\n",
    "        S[t, step] = np.array(state)                                    # Record this new state\n",
    "        E[t, step] = Energy                                             # Record the energy of this step\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 10000, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.shape # We have dataset S now , where S[T][i][j] is spin value of jth site in ith data at temperature T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 842.,    0., 1128.,  297., 1619.,  690.,  939., 1007., 1182.,\n",
       "           0.,  883.,  376.,  317.,  211.,  169.,  224.,   67.,   11.,\n",
       "          20.,   18.]),\n",
       " array([-2.   , -1.964, -1.928, -1.892, -1.856, -1.82 , -1.784, -1.748,\n",
       "        -1.712, -1.676, -1.64 , -1.604, -1.568, -1.532, -1.496, -1.46 ,\n",
       "        -1.424, -1.388, -1.352, -1.316, -1.28 ]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(E[100]/N,bins=20)     # Try to plot energy distribution of samples given some temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now We have dataset sampled from Boltzmann distribution. State $S[t][i][j]$ and energy $E[t][i]$ where t refer to t-th temperature, i for i-th data, j for j-th lattice site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on theoretical study, the critical temperature of Ising model is $T_{c} = \\frac{2}{ln(1+\\sqrt{2})}\\approx 2.2692ô°”$. We will try to classify states by paramagnetism (T>Tc) and ferromagnetism.(T<Tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.269185314213022"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tc = 2.0/math.log(1.0+2**(1/2.0))\n",
    "Tc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset into two phase categories. To do so, we search for the t point that represent Tc and seperate dataset by it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(T), nsteps, N))\n",
    "y = np.zeros((len(T), nsteps, 2))\n",
    "for t in range(len(T)):\n",
    "    if T[t] < Tc: \n",
    "            x[t] = x[t] + S[t]\n",
    "            y[t] = y[t] + [1.0, 0.0]\n",
    "    else: \n",
    "            x[t] = x[t] + S[t]\n",
    "            y[t] = y[t] + [0.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the input data $x[t][i][j]$ and the label $y[t][i]$ are consistent in t and i index. What we wanna feed into Machine learning is spin configuration $(x_{[t][i]})[j]$ and its label $y_{[t][i]}$. We can unfold the t,i index by numpy.reshape function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.reshape(x, (len(T)*nsteps, N))\n",
    "y_data = np.reshape(y, (len(T)*nsteps, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000000, 100), (2000000, 2))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've represented our \"raw data\" S by (x_data, y_data). We now separate it into training set (x_data_train, y_data_train) and test set (x_data_test, y_data_test)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing so, we need to shuffle our data. Be careful to keep the one-to-one correspondance of x and y unchanged when shuffling. This can be done by combining x, y to form a list of tuple (x, y) and then shuffle this list. The build-in function zip() can do this. (Note: 9,000,000 datas need 2 min to run this code.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(zip(x_data, y_data))\n",
    "random.shuffle(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have c, the full data (x,y) randomly shuffled. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we pick a portion of dataset (x,y) since we don't need so huge dataset for training Ising model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_portion = int(len(c)/500)\n",
    "x_picked = np.zeros((data_portion, N))\n",
    "y_picked = np.zeros((data_portion, 2))\n",
    "for i in range(data_portion):\n",
    "    x_picked[i] = c[i][0]\n",
    "    y_picked[i] = c[i][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_y_comined = np.array(list(zip(x_picked, y_picked)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Mismatch between array dtype ('object') and format specifier ('%.18e,%.18e')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[1;32m   1421\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1422\u001b[0;31m                     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-181-e6bbf8243851>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ising.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_y_comined\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"state,phase\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[1;32m   1424\u001b[0m                     raise TypeError(\"Mismatch between array dtype ('%s') and \"\n\u001b[1;32m   1425\u001b[0m                                     \u001b[0;34m\"format specifier ('%s')\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m                                     % (str(X.dtype), format))\n\u001b[0m\u001b[1;32m   1427\u001b[0m                 \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Mismatch between array dtype ('object') and format specifier ('%.18e,%.18e')"
     ]
    }
   ],
   "source": [
    "np.savetxt(\"ising.csv\",x_y_comined , delimiter=',', header=\"state,phase\", comments=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_picked, y_picked, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3200, 100), (800, 100), (3200, 2), (800, 2))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For later use, we transpose the data x and y. (Since in training, we'll do Wx+b where component of data are summed. Thus component index should be moved ahead.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.T\n",
    "x_test = x_test.T\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 3200), (100, 800), (2, 3200), (2, 800))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN From scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The archetecture of NN is $a^{(\\ell)} = g(z^{(\\ell)}) = g(w^{(\\ell)}a^{(\\ell-1)}+b^{(\\ell)})$, where $g= \\frac{1}{1+e^{-z}}$ is logistic function. Note that $\\ell= 1,2,...,L$. $w^{(\\ell)}$ and $b^{(\\ell)}$ are weight and bias of $\\ell$-th layer. $a^{(0)}$ is just input data x and $a^{(L)}$ is just predicted label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build NN by hand , we have to build some helper functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define the parameter initilizer which can generate initialization of parameters of any NN depth.\n",
    "We input dimension of every layer(a list), it output the initialized parameters (a dictionary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_nn_parameters(layer_dims):\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)                     # number of layers in the network\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1])*0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "def activation_list(ActList):           # If input is (3,1), output will be ['relu', 'relu', 'relu', 'sigmoid']\n",
    "    act_list = []\n",
    "    a = ActList[0]\n",
    "    b = ActList[1]\n",
    "    for l in range(1, a+b+1):\n",
    "        if l <= a:\n",
    "            act_list += ['relu']\n",
    "        else:\n",
    "            act_list += ['sigmoid']\n",
    "    return act_list                       # If NN has L layers, this act_list will be indexed from [0] to [L-1]\n",
    "\n",
    "\n",
    "def sigmoid(Z):\n",
    "    A = 1.0/(1+math.e**(-Z))\n",
    "    return A\n",
    "\n",
    "def sigmoid_backward(dA, A):\n",
    "    dZ = dA*A*(1-A)\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, to build the whole feed-forward function. We consider the process $a^{(\\ell)} = g(w^{(\\ell)}a^{(\\ell-1)}+b^{(\\ell)})$ for $\\ell$-th layer and stack such layer from $\\ell=0$ to $\\ell=L$ together to form the whole feed-forward function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l-th layer forward propagation \n",
    "# Input W is (n_l, n_l-1), A_prev is (n_l-1, m), b is (n_l, 1)  ;   PS. m is number of datas\n",
    "# Output Z is (n_l, m)\n",
    " \n",
    "\n",
    "# Input X is (N, m) where N is # of components of data, m is # of datas\n",
    "def forward_one(A_prev, W, b, activation):\n",
    "    Z = np.dot(W, A_prev) + b\n",
    "    if activation == \"sigmoid\":            # Note that we haven't applied other activation function\n",
    "        A = sigmoid(Z)\n",
    "        cache = (A, Z, A_prev, W, b)       # Use a tuple to store A,W,b at this layer for later use in GD.\n",
    "    return A, cache\n",
    "\n",
    "# Input X is (N, m) where N is # of components of data, m is # of datas\n",
    "def forward_L(X, parameters, activation):\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2           # number of layers in the neural network\n",
    "    \n",
    "    # Implement [forward_one]*(L-1). Add \"cache\" to the \"caches\" list.\n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        A, cache = forward_one(A_prev, parameters[\"W\"+str(l)] , parameters[\"b\"+str(l)] , activation )\n",
    "        caches.append(list(cache))\n",
    "    AL, cache = forward_one(A, parameters[\"W\"+str(L)] , parameters[\"b\"+str(L)] , activation)\n",
    "    caches.append(list(cache))   \n",
    "    # Worth to remind : caches[l] = [A, Z, A_prev, W, b]  for l=0~L\n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have built full forward propagation. Then we define a cost function for this output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y, cost_function):\n",
    "    if cost_function == \"cross_entropy\":            # Note that we haven't applied other kind of cost function\n",
    "        cost = -1/(Y.shape[1])*np.sum(Y*np.log(AL)+(1-Y)*np.log(1-AL))\n",
    "        \n",
    "    cost = np.squeeze(cost)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After complete the NN architecture, we now build the training process which is called backward propagation in NN. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the same as forward prop., we deal with l-th layer backward prop. and then stack such layer from $\\ell=0$ to $\\ell=L$ together to form the whole feed-forward function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In back prop. we will make use of cache in forward prop.\n",
    "\n",
    "def backward_one(dA, cache, activation):\n",
    "    A, Z, A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    if activation == \"sigmoid\":           # Note that we haven't included other activation function\n",
    "        dZ = sigmoid_backward(dA, A)\n",
    "        dW = 1/m*np.dot(dZ,A_prev.T)\n",
    "        db = 1/m*np.sum(dZ,axis=1,keepdims=True)\n",
    "        dA_prev = np.dot(W.T,dZ)\n",
    "        \n",
    "    return dA_prev, dW, db     \n",
    "\n",
    "def backward_L(AL, Y, caches, activation):\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
    "    # To start back prop., we need to compute dAL by hand\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))         # This is the case for the cross entrypy\n",
    "    \n",
    "    # Lth layer backward_one gradients. \n",
    "    #Inputs: \"dAL, current_cache\". Outputs: \"grads[\"dAL-1\"], grads[\"dWL\"], grads[\"dbL\"]\n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = backward_one(dAL, current_cache , activation)\n",
    "    # Implement [backward_one]*(L-1)\n",
    "    for l in reversed(range(L-1)):\n",
    "        #l-th layer\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = backward_one(grads[\"dA\" + str(l+1)], current_cache , activation)\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we update the weight and bias by this grads. $W^{[\\ell]}=W^{[\\ell]} - \\lambda dW^{[\\ell]}$ and $b^{[\\ell]}=b^{[\\ell]} - \\lambda db^{[\\ell]}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    L = len(parameters) // 2 \n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate*grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate*grads[\"db\" + str(l+1)]\n",
    "    return parameters    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, build the training model composed of these helper funtions, which looks like this following sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) initialize_nn_parameters(layer_dims) $\\Longrightarrow$ parameters={W,b}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) forward_L(x_train, parameters, activation) $\\Longrightarrow$ AL, caches={A, Z, A_prev, W, b}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) compute_cost(AL, y_train, cost_function) $\\Longrightarrow$ cost   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) backward_L(AL, y-train, caches, activation) $\\Longrightarrow$ grads={dA, dW, db}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) update_parameters(parameters, grads, learning_rate) $\\Longrightarrow$ parameters={W,b}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try two layer NN, we set up some \"hyper-parameters\" of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = []                              # To record the cost over epoches for later graph plot\n",
    "m = x_train.shape[1]                    # Number of examples\n",
    "epoches = 3000\n",
    "learning_rate = 0.01\n",
    "layers_dims = (N, 100, 2)               # NN structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 1.385068\n",
      "Cost after iteration 100: 1.301457\n",
      "Cost after iteration 200: 1.265188\n",
      "Cost after iteration 300: 1.188611\n",
      "Cost after iteration 400: 1.061132\n",
      "Cost after iteration 500: 0.928360\n",
      "Cost after iteration 600: 0.836884\n",
      "Cost after iteration 700: 0.783480\n",
      "Cost after iteration 800: 0.751952\n",
      "Cost after iteration 900: 0.732022\n",
      "Cost after iteration 1000: 0.718457\n",
      "Cost after iteration 1100: 0.708595\n",
      "Cost after iteration 1200: 0.701019\n",
      "Cost after iteration 1300: 0.694930\n",
      "Cost after iteration 1400: 0.689856\n",
      "Cost after iteration 1500: 0.685505\n",
      "Cost after iteration 1600: 0.681691\n",
      "Cost after iteration 1700: 0.678287\n",
      "Cost after iteration 1800: 0.675209\n",
      "Cost after iteration 1900: 0.672395\n",
      "Cost after iteration 2000: 0.669802\n",
      "Cost after iteration 2100: 0.667397\n",
      "Cost after iteration 2200: 0.665153\n",
      "Cost after iteration 2300: 0.663050\n",
      "Cost after iteration 2400: 0.661073\n",
      "Cost after iteration 2500: 0.659208\n",
      "Cost after iteration 2600: 0.657444\n",
      "Cost after iteration 2700: 0.655772\n",
      "Cost after iteration 2800: 0.654182\n",
      "Cost after iteration 2900: 0.652669\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_nn_parameters(layers_dims)\n",
    "\n",
    "for epo in range(0, epoches):\n",
    "    \n",
    "    AL, caches = forward_L(x_train, parameters, activation = \"sigmoid\")  \n",
    "    cost = compute_cost(AL, y_train, cost_function = \"cross_entropy\")\n",
    "    grads = backward_L(AL, y_train, caches, activation = \"sigmoid\")\n",
    "    parameters = update_parameters(parameters, grads, learning_rate)\n",
    "    \n",
    "    if epo % 100 == 0:\n",
    "        print (\"Cost after iteration %i: %f\" %(epo, cost))\n",
    "        costs.append(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learned parameters is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 0.02044446,  0.01796545,  0.01516966, ...,  0.02378165,\n",
       "          0.02454109,  0.01318137],\n",
       "        [-0.02189228, -0.02683816, -0.00974925, ...,  0.00039355,\n",
       "         -0.01443828, -0.01425024],\n",
       "        [ 0.03857717, -0.00103028,  0.02394997, ...,  0.02318799,\n",
       "          0.00796808,  0.01360305],\n",
       "        ...,\n",
       "        [ 0.01276818,  0.02111742,  0.01019426, ...,  0.02548053,\n",
       "          0.01497349,  0.01950911],\n",
       "        [-0.00880322,  0.00663747, -0.0151539 , ..., -0.01769319,\n",
       "         -0.02226783,  0.00547144],\n",
       "        [-0.02230102, -0.01729107, -0.01239316, ..., -0.01885681,\n",
       "         -0.0179742 , -0.01369526]]), 'b1': array([[ 0.02425434],\n",
       "        [-0.01087423],\n",
       "        [ 0.03731874],\n",
       "        [ 0.02289231],\n",
       "        [ 0.02482015],\n",
       "        [ 0.03143008],\n",
       "        [ 0.00039957],\n",
       "        [-0.00630764],\n",
       "        [ 0.00562742],\n",
       "        [ 0.00048941],\n",
       "        [-0.0408732 ],\n",
       "        [-0.00225806],\n",
       "        [-0.01359794],\n",
       "        [ 0.00927689],\n",
       "        [ 0.00930707],\n",
       "        [-0.0197466 ],\n",
       "        [-0.01769774],\n",
       "        [ 0.02688008],\n",
       "        [-0.01795685],\n",
       "        [ 0.00445516],\n",
       "        [-0.00425275],\n",
       "        [ 0.03417275],\n",
       "        [-0.00786755],\n",
       "        [ 0.01872476],\n",
       "        [-0.01188656],\n",
       "        [-0.00050204],\n",
       "        [ 0.00494382],\n",
       "        [ 0.00136401],\n",
       "        [-0.00641691],\n",
       "        [ 0.00249013],\n",
       "        [-0.00563056],\n",
       "        [ 0.02170566],\n",
       "        [-0.02026663],\n",
       "        [-0.01565065],\n",
       "        [ 0.01448496],\n",
       "        [-0.00356057],\n",
       "        [ 0.0192881 ],\n",
       "        [ 0.00124824],\n",
       "        [ 0.0433508 ],\n",
       "        [-0.01056251],\n",
       "        [ 0.00993875],\n",
       "        [-0.00453185],\n",
       "        [ 0.02671229],\n",
       "        [ 0.00214854],\n",
       "        [ 0.01115064],\n",
       "        [ 0.00667744],\n",
       "        [ 0.03443778],\n",
       "        [-0.02057814],\n",
       "        [ 0.00413282],\n",
       "        [-0.02050891],\n",
       "        [ 0.00995825],\n",
       "        [-0.01182188],\n",
       "        [-0.04692058],\n",
       "        [ 0.00666147],\n",
       "        [ 0.00434907],\n",
       "        [-0.0172345 ],\n",
       "        [ 0.00802202],\n",
       "        [-0.03052363],\n",
       "        [ 0.0052849 ],\n",
       "        [ 0.03862686],\n",
       "        [ 0.00127087],\n",
       "        [-0.0411396 ],\n",
       "        [-0.02954294],\n",
       "        [ 0.04296183],\n",
       "        [ 0.00182568],\n",
       "        [ 0.00099148],\n",
       "        [ 0.03556682],\n",
       "        [-0.012588  ],\n",
       "        [ 0.01338303],\n",
       "        [ 0.01600157],\n",
       "        [ 0.00158722],\n",
       "        [-0.01124512],\n",
       "        [-0.00027505],\n",
       "        [-0.0379886 ],\n",
       "        [-0.0344107 ],\n",
       "        [ 0.01106545],\n",
       "        [-0.00184348],\n",
       "        [-0.0122713 ],\n",
       "        [ 0.01044742],\n",
       "        [ 0.0035983 ],\n",
       "        [ 0.00875275],\n",
       "        [ 0.02052666],\n",
       "        [-0.00896546],\n",
       "        [ 0.00623359],\n",
       "        [ 0.02607884],\n",
       "        [-0.00703131],\n",
       "        [ 0.044636  ],\n",
       "        [-0.00991517],\n",
       "        [-0.01585096],\n",
       "        [-0.0536068 ],\n",
       "        [-0.02880001],\n",
       "        [-0.01003677],\n",
       "        [-0.02464994],\n",
       "        [-0.02778772],\n",
       "        [-0.00523593],\n",
       "        [ 0.02886696],\n",
       "        [-0.02425172],\n",
       "        [ 0.00911613],\n",
       "        [-0.00413221],\n",
       "        [-0.02818944]]), 'W2': array([[-0.21402476,  0.09427108, -0.25798495, -0.22073684, -0.21480824,\n",
       "         -0.23544981, -0.02619629,  0.05632959, -0.10539867, -0.0541279 ,\n",
       "          0.18704663,  0.03611965,  0.0926049 , -0.14063887, -0.1359112 ,\n",
       "          0.12646273,  0.11297513, -0.22517848,  0.11163764, -0.0889411 ,\n",
       "          0.03756767, -0.25361129,  0.06329368, -0.17938908,  0.0814776 ,\n",
       "         -0.004067  , -0.102062  , -0.05954501,  0.06071191, -0.07917434,\n",
       "          0.05853008, -0.19565391,  0.1277645 ,  0.10147526, -0.18654291,\n",
       "          0.03725196, -0.19391112, -0.05165538, -0.2663517 ,  0.08969266,\n",
       "         -0.14243265,  0.04056462, -0.22320208, -0.06933335, -0.15005823,\n",
       "         -0.12112963, -0.25279358,  0.13163231, -0.1026787 ,  0.13086202,\n",
       "         -0.1480327 ,  0.09132703,  0.21272895, -0.11855183, -0.10978883,\n",
       "          0.10194522, -0.13212441,  0.16005895, -0.11237845, -0.26403803,\n",
       "         -0.04445859,  0.17935895,  0.16281079, -0.28071963, -0.06240646,\n",
       "         -0.04070977, -0.26189254,  0.08040375, -0.16784343, -0.169367  ,\n",
       "         -0.04868175,  0.09127124, -0.0039821 ,  0.18322341,  0.17564804,\n",
       "         -0.14624047,  0.02453357,  0.09671326, -0.14898592, -0.09113315,\n",
       "         -0.1385779 , -0.20105437,  0.07980798, -0.12204156, -0.21787206,\n",
       "          0.06570848, -0.2886618 ,  0.08585996,  0.10909286,  0.22864219,\n",
       "          0.15961597,  0.07675672,  0.14738945,  0.15787969,  0.05233294,\n",
       "         -0.22539348,  0.15164491, -0.13825035,  0.03346188,  0.15485571],\n",
       "        [ 0.20972699, -0.07663717,  0.26010058,  0.1929035 ,  0.21519435,\n",
       "          0.24251728,  0.03202547, -0.06199324,  0.12152226,  0.00785701,\n",
       "         -0.20066281, -0.01068116, -0.10446504,  0.13922112,  0.14537492,\n",
       "         -0.12026183, -0.11920587,  0.21785912, -0.12105041,  0.11480037,\n",
       "         -0.05028227,  0.24444343, -0.0743358 ,  0.19967006, -0.09944558,\n",
       "          0.00441377,  0.11355232,  0.05168131, -0.05797238,  0.07576007,\n",
       "         -0.04916959,  0.20706514, -0.12335908, -0.11279261,  0.15303014,\n",
       "         -0.03726409,  0.18933008,  0.05429073,  0.29355285, -0.0758952 ,\n",
       "          0.14564008, -0.05173609,  0.21860979,  0.07387494,  0.15339047,\n",
       "          0.12320457,  0.24856566, -0.12255423,  0.09401638, -0.1219486 ,\n",
       "          0.13973673, -0.08765339, -0.21273149,  0.12527526,  0.09291247,\n",
       "         -0.12508306,  0.13169477, -0.16156418,  0.10781161,  0.26409507,\n",
       "          0.06171251, -0.21268512, -0.15500012,  0.27511365,  0.06862446,\n",
       "          0.05092138,  0.24450198, -0.10708535,  0.15903231,  0.18395479,\n",
       "          0.07396995, -0.08300059,  0.01614071, -0.18720412, -0.17358723,\n",
       "          0.15421863, -0.0117196 , -0.08696077,  0.14556604,  0.09384982,\n",
       "          0.13534803,  0.1931085 , -0.06904095,  0.11490132,  0.21928712,\n",
       "         -0.06133417,  0.27932678, -0.07362217, -0.10659441, -0.23495434,\n",
       "         -0.15274716, -0.08450736, -0.13416598, -0.14764561, -0.05124589,\n",
       "          0.23496923, -0.12992378,  0.13964144, -0.05150042, -0.15214468]]), 'b2': array([[-0.16108285],\n",
       "        [ 0.15753346]])}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can plot the learning progress through plotting cost over epoches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd4HOW59/HvrV4suUrCvWFcaAGEjQkEbEwCKRBCQiCEkpCAk5Ce9yQ5yUlIcvK+OSkn5aRQQk2BAIHEkMKhm4ANyGAbg7GxjYtsY8lVktWl+/1jRvJaqBlrNVt+n+vaa3dnnp29x2vtb+eZmWfM3REREQHIiLoAERFJHAoFERHppFAQEZFOCgUREemkUBARkU4KBRER6aRQkLRgZv8wsyuirkMk0SkUJK7MbKOZLYi6Dnc/191vj7oOADN7wsw+MQjvk2tmt5hZjZm9YWZf6qP9F8N2+8LX5cbM+56ZvWRmrWZ2Xbxrl+goFCTpmVlW1DV0SKRagOuAacBEYB7wb2Z2TncNzexdwNeAs4BJwBTgOzFN1gH/BvwtfuVKIlAoSGTM7L1mttzM9prZM2Z2XMy8r5nZejOrNbNXzOyCmHlXmtnTZvZTM9sNXBdO+5eZ/djM9pjZ62Z2bsxrOn+d96PtZDNbHL73I2b2KzP7fQ/rcKaZVZrZV83sDeBWMxtuZg+aWXW4/AfNbFzY/vvA6cAvzazOzH4ZTp9hZg+b2W4zW2NmFw3AP/HlwPfcfY+7rwZuAq7soe0VwM3u/rK77wG+F9vW3W93938AtQNQlyQwhYJEwsxOBG4BrgFGAjcAi2K6LNYTfHkOJfjF+nszGx2ziDnABqAU+H7MtDXAKOCHwM1mZj2U0FvbPwLPhXVdB1zWx+ocAYwg+EV+NcHf1a3h8wlAA/BLAHf/BvAUcK27D3H3a82sEHg4fN9S4BLg12Z2dHdvZma/DoO0u9vKsM1wYAywIualK4BulxlO79q2zMxG9rHukmIUChKVTwI3uPuz7t4W9vc3AacAuPs97r7N3dvd/U/Aa8DsmNdvc/f/cfdWd28Ip21y95vcvQ24HRgNlPXw/t22NbMJwMnAt9y92d3/BSzqY13agW+7e5O7N7j7Lnf/s7vXu3stQWid0cvr3wtsdPdbw/V5Afgz8MHuGrv7p919WA+3jq2tIeH9vpiX7gOKeqhhSDdt6aW9pCiFgkRlIvDl2F+5wHiCX7eY2eUxXUt7gWMIftV32NLNMt/oeODu9eHDId20663tGGB3zLSe3itWtbs3djwxswIzu8HMNplZDbAYGGZmmT28fiIwp8u/xaUEWyBvVV14XxwzrZieu3/qumlLL+0lRSkUJCpbgO93+ZVb4O53mtlEgv7va4GR7j4MWAXEdgXFa3jf7cAIMyuImTa+j9d0reXLwHRgjrsXA+8Ip1sP7bcAT3b5txji7p/q7s3M7Ppwf0R3t5cBwv0C24HjY156PPByD+vwcjdtd7j7rp5XW1KRQkEGQ7aZ5cXcsgi+9Bea2RwLFJrZe8ysCCgk+OKsBjCzjxFsKcSdu28CKgh2XueY2VzgfYe4mCKC/Qh7zWwE8O0u83cQHN3T4UHgKDO7zMyyw9vJZjazhxoXhqHR3S12n8EdwDfDHd8zCLrsbuuh5juAq8xsVrg/4puxbcOa8gi+M7LCz7GnLR9JYgoFGQx/J/iS7Lhd5+4VBF9SvwT2EBzyeCWAu78C/ARYQvAFeizw9CDWeykwF9gF/CfwJ4L9Hf31MyAf2AksBf7ZZf7PgQ+GRyb9Itzv8E7gYmAbQdfWfwG5HJ5vE+yw3wQ8CfzI3f8JYGYTwi2LCQDh9B8Cj4ftN3FwmN1E8NldAnwjfNzXDnhJQqaL7Ij0zsz+BLzq7l1/8YukHG0piHQRdt1MNbMMC072Oh/4S9R1iQyGRDr7UiRRHAHcR3CeQiXwKXd/MdqSRAaHuo9ERKSTuo9ERKRT0nUfjRo1yidNmhR1GSIiSWXZsmU73b2kr3ZJFwqTJk2ioqIi6jJERJKKmW3qTzt1H4mISKe4hYIFF+moMrNVfbQ72czazKzbwb9ERGTwxHNL4Tag2wt6dAhPk/8v4KE41iEiIv0Ut1Bw98XA7j6afZZgiOCqeNUhIiL9F9k+BTMbC1wAXN+PtlebWYWZVVRXV8e/OBGRNBXljuafAV8NL3LSK3e/0d3L3b28pKTPI6pEROQtivKQ1HLgrvAKiKOAd5tZq7trjBkRkYhEtqXg7pPdfZK7TwLuBT4dz0DYUF3Hdx54mZa29ni9hYhI0ovnIal3EoyHP93MKs3sKjNbaGYL4/Wevdm4az+3Pr2RB1Zsi+LtRUSSQty6j9z9kkNoe2W86ugwb3op08uKuOHJDVxwwljCbisREYmRNmc0mxnXnDGFNTtqeXyNjoAVEelO2oQCwPuOH8PYYflc/8SGqEsREUlIaRUK2ZkZXHXaZJ7buJtlm/o6r05EJP2kVSgAXDx7PMMKsvmNthZERN4k7UKhICeLy+dO4pHVO3htR23U5YiIJJS0CwWAK0+dRF52Bjcs1taCiEistAyFEYU5XHzyBP66fCvb9zVEXY6ISMJIy1AAuOq0ybQ73PzU61GXIiKSMNI2FMaPKOB9x43mzuc2s6++JepyREQSQtqGAsA1Z0xlf3Mbv1u6MepSREQSQlqHwszRxZw5vYRbn95IY0ufI3iLiKS8tA4FgIVnTGXX/mbuWVYZdSkiIpFL+1CYM3kEbxs/jJsWb6BVw2qLSJpL+1AwMxaeMZXNu+v5x6o3oi5HRCRSaR8KAO+cVcaUkkKuf3I97h51OSIikVEoABkZxjXvmMLL22r417qdUZcjIhIZhULo/SeMpaw4l+ufXB91KSIikVEohHKzMvn42yfz9LpdrKzcG3U5IiKRiOc1mm8xsyozW9XD/PPNbKWZLTezCjM7LV619NdH5kygKC9LWwsikrbiuaVwG3BOL/MfBY5397cBHwd+G8da+qUoL5vLTpnIP1a9wes790ddjojIoItbKLj7YqDHy5u5e50fONSnEEiIw34+9vbJZGdm8J8PvkJzq85bEJH0Euk+BTO7wMxeBf5GsLXQU7urwy6miurq6rjWVFKUy9fPncGjr1bxyTsqaGjW8Bcikj4iDQV3v9/dZwDvB77XS7sb3b3c3ctLSkriXtfH3j6ZH3zgWJ56rZrLbn6WfQ0aRVVE0kNCHH0UdjVNNbNRUdfS4eLZE/jlR05kReVeLr5xKdW1TVGXJCISd5GFgpkdaWYWPj4RyAF2RVVPd9597Gh+e8XJbNy5n4tuWELlnvqoSxIRiat4HpJ6J7AEmG5mlWZ2lZktNLOFYZMLgVVmthz4FfBhT8AxJs44qoTff2I2O+ua+ND1S1hXVRd1SSIicWMJ+D3cq/Lycq+oqBj0931lWw2X3/Ic7e7c/rHZHDtu6KDXICLyVpnZMncv76tdQuxTSAazxhRzz8K55GdncslNS1m6IaF6ukREBoRC4RBMHlXIvZ+ayxFD87jilud4dPWOqEsSERlQCoVDNHpoPndfM5ejyoq45nfL+OvyrVGXJCIyYBQKb8GIwhz++Mk5nDRxOF/403INoCciKUOh8BYV5WXz2yvKGZqfzU8fXht1OSIiA0KhcBiK8rK5+h1TeHxNNS9s3hN1OSIih02hcJiumDuJEYU52loQkZSgUDhMhblZLDxjCk+9tpPnN/Y4KKyISFJQKAyAy06ZxKghudpaEJGkp1AYAPk5mXzqzKk8s34XS9brpDYRSV4KhQFy6ZwJlBbl8tNH1pJsQ4eIiHRQKAyQvOxMPjPvSJ57fTfPaGtBRJKUQmEAffjk8Ywemsd/P6ytBRFJTgqFAdSxtbBs0x4Wv7Yz6nJERA6ZQmGAXVQ+nrHD8rW1ICJJSaEwwHKyMvjs/CNZsWUvj6+pirocEZFDolCIgwtPGsf4EdpaEJHko1CIg+zMDD43fxqrttbw8Cu65oKIJI94XqP5FjOrMrNVPcy/1MxWhrdnzOz4eNUShQtOGMukkQX89JHXaG/X1oKIJId4bincBpzTy/zXgTPc/Tjge8CNcaxl0GVlZvD5BdNYvb2Gh15+I+pyRET6JW6h4O6LgR5HiHP3Z9y9Y7zppcC4eNUSlfOOH8uUkkJ++shabS2ISFJIlH0KVwH/6GmmmV1tZhVmVlFdXT2IZR2ezAzjCwuOYu2OOv720vaoyxER6VPkoWBm8whC4as9tXH3G9293N3LS0pKBq+4AfCeY0dzVNkQfvbIWtq0tSAiCS7SUDCz44DfAue7e0oOGNSxtbC+ej+LVmyNuhwRkV5FFgpmNgG4D7jM3VP6QgTnHH0ER5YO4Y/Pbo66FBGRXsXzkNQ7gSXAdDOrNLOrzGyhmS0Mm3wLGAn82syWm1lFvGqJWkaG8e5jR7Ns0x5272+OuhwRkR5lxWvB7n5JH/M/AXwiXu+faM6eWcYvHn2Nx1+t4sKTUu5AKxFJEZHvaE4Xx4wtpqw4l0dW6wxnEUlcCoVBYmYsmFnGk2uraWxpi7ocEZFuKRQG0YJZZdQ3t7F0Q0oeaCUiKUChMIjmThlJQU6mupBEJGEpFAZRXnYm75hWwiOvVGlIbRFJSAqFQbZgVhlv1DSyamtN1KWIiLyJQmGQzZ9RSobBw+pCEpEEpFAYZCMKcyifOIJHdPEdEUlACoUILJhVyivba9i6tyHqUkREDqJQiMCCmWUAPKouJBFJMAqFCEwpGcKUkkJdv1lEEo5CISJnzyxj6YZd1Da2RF2KiEgnhUJEFswqo6XNWbx2Z9SliIh0UihE5MQJwxlekK2zm0UkoSgUIpKZYcyfUcZjr1bR2tYedTkiIoBCIVJnzyplX0MLz2/cE3UpIiKAQiFSp08rISczQ11IIpIwFAoRKszN4tQjR/LI6h0aIE9EEkI8r9F8i5lVmdmqHubPMLMlZtZkZl+JVx2JbsHMMjbtqmddVV3UpYiIxHVL4TbgnF7m7wY+B/w4jjUkvLNmlgIaIE9EEkPcQsHdFxN88fc0v8rdnwfS+uyt0UPzOXbsUA2QJyIJISn2KZjZ1WZWYWYV1dXVUZcz4M6eVcaLW/ZSXdsUdSkikuaSIhTc/UZ3L3f38pKSkqjLGXALZpbhDo+/WhV1KSKS5pIiFFLdzNFFjB2Wr/0KIhI5hUICMDMWzCzlqdeqaWxpi7ocEUlj8Twk9U5gCTDdzCrN7CozW2hmC8P5R5hZJfAl4Jthm+J41ZPoFswqo7GlnafXaYA8EYlOVrwW7O6X9DH/DWBcvN4/2cyZPJIhuVk8snoHZ4UX4RERGWzqPkoQOVkZnDG9hEdWV9HerrObRSQaCoUEcvbMMqprm1hRuTfqUkQkTSkUEsiZ00vIzDANkCcikVEoJJBhBTmcPGk4j7yi8xVEJBoKhQSzYGYZa3bUsmV3fdSliEgaUigkmI4jjx7T2c0iEgGFQoKZPKqQyaMKFQoiEgmFQgKaN72UJRt2Ud/cGnUpIpJm+hUKZvah/kyTgTF/RinNre08s25X1KWISJrp75bC1/s5TQbA7MkjKMzJ5LE16kISkcHV6zAXZnYu8G5grJn9ImZWMaC+jTjJycrgtGmjePzVKtwdM4u6JBFJE31tKWwDKoBGYFnMbRHwrviWlt7mzyhl+75GXn2jNupSRCSN9Lql4O4rgBVm9kd3bwEws+HAeHffMxgFpqt504NrNz/2ahUzR6ft4LEiMsj6u0/hYTMrNrMRwArgVjP77zjWlfZKi/M4ZmyxrsYmIoOqv6Ew1N1rgA8At7r7ScCC+JUlAPOnl/LC5j3s2d8cdSkikib6GwpZZjYauAh4MI71SIx5M0ppd1j8WnXUpYhImuhvKHwXeAhY7+7Pm9kU4LX4lSUAx48bxsjCHJ3dLCKDpl9XXnP3e4B7Yp5vAC6MV1ESyMgwzphewmOvVtHW7mRm6NBUEYmv/p7RPM7M7jezKjPbYWZ/NrNeL6VpZreE7Vf1MN/M7Bdmts7MVprZiW9lBVLd/Bml7K1v4cXNOthLROKvv91HtxKcmzAGGAs8EE7rzW3AOb3MPxeYFt6uBn7Tz1rSyunTggvvqAtJRAZDf0OhxN1vdffW8HYbUNLbC9x9MbC7lybnA3d4YCkwLNyZLTGG5mdTPnG4QkFEBkV/Q2GnmX3UzDLD20eBwx2tbSywJeZ5ZTjtTczsajOrMLOK6ur0OxJn/oxSXn2jlm17G6IuRURSXH9D4eMEh6O+AWwHPgh87DDfu7u9pt5dQ3e/0d3L3b28pKTXDZSUNH9GcHbz4xogT0TirL+h8D3gCncvcfdSgpC47jDfuxIYH/N8HMFYS9LFkaVDGDc8X2c3i0jc9TcUjosd68jddwMnHOZ7LwIuD49COgXY5+7bD3OZKcnMmD+jlKfX7aKxpS3qckQkhfU3FDLCgfAACMdA6mvY7TuBJcB0M6s0s6vMbKGZLQyb/B3YAKwDbgI+fcjVp5F5M0ppaGlj6QZdeEdE4qdfJ68BPwGeMbN7Cfr9LwK+39sL3P2SPuY78Jl+vn/amztlJHnZGTz+ahVnhiOoiogMtH5tKbj7HQRnMO8AqoEPuPvv4lmYHCwvO5O3Tx3FY2uCC++IiMRDf7cUcPdXgFfiWIv0Yd6MUh59tYr11XUcWVoUdTkikoL6u09BEsC8GQcuvCMiEg8KhSQydlg+M44oUiiISNwoFJLMvBmlVGzcQ01jS9SliEgKUigkmfkzSmltd55auzPqUkQkBSkUkswJ44cxND9bXUgiEhcKhSSTlZnBGUeV8OTaKtrbdWiqiAwshUISmj+jlJ11zazcui/qUkQkxSgUktAZR5WQYTo0VUQGnkIhCQ0vzOGECcM1aqqIDDiFQpKaP6OUl7buo6q2MepSRCSFKBSS1LxwULwn1qTflehEJH4UCklq5ugiRg/N4+8v6RIUIjJwFApJysz4UPl4nlxbzcad+6MuR0RShEIhiV06ZwKZZvxu6aaoSxGRFKFQSGJlxXmce+xo7q7Ywv6m1qjLEZEUoFBIcleeOpHaxlbuf3Fr1KWISAqIayiY2TlmtsbM1pnZ17qZP9HMHjWzlWb2hJmNi2c9qejECcM5ekwxdyzZqCuyichhi1somFkm8CvgXGAWcImZzerS7MfAHe5+HPBd4P/Fq55UZWZcceok1u6oY8n6XVGXIyJJLp5bCrOBde6+wd2bgbuA87u0mQU8Gj5+vJv50g/nHT+G4QXZ3PbMxqhLEZEkF89QGAtsiXleGU6LtQK4MHx8AVBkZiO7LsjMrjazCjOrqK7WyVpd5WVncvHsCTyyegeVe+qjLkdEklg8Q8G6mda10/srwBlm9iJwBrAVeNNhNO5+o7uXu3t5SUnJwFeaAj56ykQAfr90c8SViEgyi2coVALjY56PA7bFNnD3be7+AXc/AfhGOE3jQb8FY4fl885ZR3DX85tpbGmLuhwRSVLxDIXngWlmNtnMcoCLgUWxDcxslJl11PB14JY41pPyLj91InvrW1i0fFvfjUVEuhG3UHD3VuBa4CFgNXC3u79sZt81s/PCZmcCa8xsLVAGfD9e9aSDuVNGMr2siNue0eGpIvLWZMVz4e7+d+DvXaZ9K+bxvcC98awhnZgZl586kW/cv4plm/ZQPmlE1CWJSJLRGc0p5oITxlKcl6XDU0XkLVEopJiCnCwuKh/PP1e9wY4aXYBHRA6NQiEFXTZ3Im3u/EGjp4rIIVIopKCJIwuZN72UPz63maZWHZ4qIv2nUEhRV5w6iZ11zboym4gcEoVCijr9yFFMGVXI7c+oC0lE+k+hkKIyMozL505k+Za9rNiyN+pyRCRJKBRS2IUnjaMwJ5PbdXiqiPSTQiGFFeVlc+FJ43hw5XZ21jVFXY6IJAGFQoq7fO4kmtvaufNZjZ4qIn1TKKS4I0uHcPq0Ufz+2U00t7ZHXY6IJDiFQhq4+h1T2FHTxE/+d03UpYhIglMopIHTp5Vw6ZwJ3LB4A4vX6sp1ItIzhUKa+I/3zuKosiF86e4VVNdqp7OIdE+hkCbysjP5n0tOpLaxhS/fs4L2dl1vQUTeTKGQRqYfUcR/vHcWi9dWc/O/Xo+6HBFJQAqFNHPpnAmcc/QR/PChV1lZqTOdReRgCoU0Y2b84MJjKRmSy2fvfJG6ptaoSxKRBBLXUDCzc8xsjZmtM7OvdTN/gpk9bmYvmtlKM3t3POuRwLCCHH528Qls2V3Pt/6yKupyRCSBxC0UzCwT+BVwLjALuMTMZnVp9k3gbnc/AbgY+HW86pGDzZ48gs+fdRT3vbiV+16ojLocEUkQ8dxSmA2sc/cN7t4M3AWc36WNA8Xh46HAtjjWI11cO/9IZk8ewX/8ZRWv79wfdTkikgDiGQpjgS0xzyvDabGuAz5qZpXA34HPdrcgM7vazCrMrKK6WidfDZTMDONnH34bWZkZfO7OFzUMhojENRSsm2ldD46/BLjN3ccB7wZ+Z2Zvqsndb3T3cncvLykpiUOp6WvMsHx++MHjeGnrPn700KtRlyMiEYtnKFQC42Oej+PN3UNXAXcDuPsSIA8YFceapBvvOvoILjtlIjc99TpPrKmKuhwRiVA8Q+F5YJqZTTazHIIdyYu6tNkMnAVgZjMJQkH9QxH4xntmMuOIIr5yzwqqahujLkdEIhK3UHD3VuBa4CFgNcFRRi+b2XfN7Lyw2ZeBT5rZCuBO4Ep31/gLEQiGwTiBuqZWLr/5Obbsro+6JBGJgCXbd3B5eblXVFREXUbKeuq1aj7zhxfIzDB+demJnDpVvXkiqcDMlrl7eV/tdEazHOT0aSUsuvY0Rg7J5bKbn+O2p18n2X44iMhbp1CQN5k0qpD7P30q86aXct0Dr/DVP6+kqbUt6rJEZBAoFKRbRXnZ3HjZSXzurGncXVHJxTcupapGO6BFUp1CQXqUkWF86eyj+M2lJ7LmjVre98t/8eLmPVGXJSJxpFCQPp177Gju+/Sp5GRl8OEblnJPxZa+XyQiSUmhIP0y44hiFn3mNMonDef/3LuS7zzwMq1tGhZDJNUoFKTfhhfmcMfHZ/Pxt0/m1qc3ctnNz/HajtqoyxKRAaRQkEOSlZnBt943ix9/6HhWVu7lnT9bzBf/tJyNGmVVJCVkRV2AJKcPnjSO+TNKueHJ9dy+ZCOLVmzjwhPH8tn50xg/oiDq8kTkLdIZzXLYqmob+c0T6/nDs5txdy4qH8+1849k9ND8qEsTkVB/z2hWKMiA2b6vgV89vo4/Pb8FM+PSORP41JlTKS3Ki7o0kbSnUJDIbNldz/889hp/fmEr2ZnGFXMncdXpkxUOIhFSKEjkXt+5n188+hp/Wb4VA06dOorzjh/Du445gqH52VGXJ5JWFAqSMDZU13H/i1tZtGIbm3bVk5OZwZnTSzjvbWM4a0YZ+TmZUZcokvIUCpJw3J2Vlfv46/JtPLhyG1W1TRTmZPLOo4/gvOPHcNq0UWRn6ihpkXhQKEhCa2t3nn19F4uWb+Mfq95gX0MLwwuyOeeYIzjtyBJOmTKCkUNyoy5TJGUoFCRpNLe2s3htNYtWbOPR1TvY3xwM0z29rIi5U0dyypSRnDJlBMMKciKuVCR5KRQkKbW0tfPS1n0sWb+LpRt28fzG3TS2tGMGM48oZu7UkcydMpLZU0ZQnKed1SL9lRChYGbnAD8HMoHfuvsPusz/KTAvfFoAlLr7sN6WqVBIL82t7ayo3MuS9btYsn4Xyzbvobm1nQyDo8qKOHrMUI4ZW8wxY4cyc3QxQ3J1kr5IdyIPBTPLBNYCZwOVwPPAJe7+Sg/tPwuc4O4f7225CoX01tjSxoub97J0wy5WVu7lpa017KxrAsAMJo8s5OixQzlmTBAUR48pVreTCP0PhXj+rJoNrHP3DWFBdwHnA92GAnAJ8O041iMpIC87M+hCmjqyc1pVTSOrtu1j1dYaVm3dxwub9vDAim2d88cOy+fI0iFMLRnC1NLC4L5kCKOG5GBmUayGSMKKZyiMBWKvxlIJzOmuoZlNBCYDj/Uw/2rgaoAJEyYMbJWS9EqL85hfnMf8GWWd0/bsb+blbTWs2raPV7bVsL66jude301Dy4FrTQ/Nz2ZqSRgSYWhMGlnAuOEFOndC0lY8Q6G7n2A99VVdDNzr7t1eHd7dbwRuhKD7aGDKk1Q2vDCH06aN4rRpozqntbc722saWV9Vx/rq8Fa1nyfXVnPPssqDXl9SlMv44flMGFHA+I7b8ALGj8hn9NB8MjO0hSGpKZ6hUAmMj3k+DtjWQ9uLgc/EsRYRMjKMscPyGTssn3ccVXLQvJrGFtZX1bF5dz1bdteH9w1UbNrDohXbaI/5KZKdaYwems/ooXmMGRbcB7d8Rg8L7ocXZKtrSpJSPEPheWCamU0GthJ88X+kayMzmw4MB5bEsRaRXhXnZXPChOGcMGH4m+a1tLWzfW9jEBR7gtDYsqeBN/Y18Nzru9lR00hr+8EbsLlZGZ1BUVacS1lxHiVFuZQW51FalBvcivN0tJQknLj9j3T3VjO7FniI4JDUW9z9ZTP7LlDh7ovCppcAd3mynTAhaSM7M4MJIwuYMLL7iwe1tTu76prYtq+R7Xsb2L6vke37Ou4bqdi0h6raJppb33xN64KczDAk8igpzqVkSC4jC3MYOSSXUUOC+5IhuYwckkOhAkQGgU5eExkE7s6+hhaqapuoqmmiqrbx4Mc1TVTXNbGzronaxtZul5GfncnIMChGFuYwIrwNL8hhZGEOwwtzGFGYzYjCXEYU5FCUl0WG9n1IKBEOSRWRkJkxrCCHYQU5HFVW1GvbxpY2du9vZlddMzvDoNi1v5mdteF9XRM7ahpZvb2GXfubu90CAcjMMIYXZAfvmx/eF2QfmFaQzbD8HIYXZDM0nDY0P5vCnEztD0ljCgWRBJOXncmYYfmMGdb35UzdnYYwRDpue+qDQNlT38zu/S3sa2hmz/4Wtu5t4OVt+9hb33LQobldZWUYxfnZDM3P7rwPblmdj4vzgnnBfRbFedkU5WVRnJ+tkW6TnEJBJImZGQU5WRTkZDFuePf7PLrT2NLGvoYW9tQ3s7e+hb31zexraDnotrc+fFzfzOZd+9nOwO8mAAAJ6ElEQVTX0EJNYytt7b13OednZx4UFEM6AiMvi6K8bIbkZlEUPi7Ky6IoN5yel9U5LzcrQ1srEVEoiKShvOxM8rIzKSs+tEukujt1Ta3UNrZS09hCTUMrNQ0t4eOWg6bva2ihtikIlcrd9dQ0tlLb2EJTD91dsbIyrDMkOoJiSG4WhbkH7oPHmQem5cTOz+xsl5+dqX0rh0ChICL9ZmbhL/xsxtB391Z3mlvbw2AJQqQ2DIu6plb2N7VS29RKXWMrdbH3Ta3s2t/Mxl31ne3qm3vuAuuqICeTgpwgRApygtAoDIOkICd4HLQ5MD8/J4vCnEzyczLDwAmmFWQH01J1a0ahICKDKicrgxFZwZFTh6O93dnf3Mr+prbOoNgfBsj+5lbqmtqob2plf3PHfdC2vjlos3t/M1t213dOq29ue9P5Jr3JMCjIySI/DJP87AOhktf5OLPzcX4YJrHt83OCLZngcQZ52Qfa5WVFs4WjUBCRpJSRcWCrZaA0t7Z3BkTH/f6mNhpaWg8Kj/rmNho67lu6TmtlZ10TjS0d84PphxI4HXKzMoIgCcPiI3Mm8InTpwzY+nZHoSAiEsrJyiAnK4dh/d9n328tbe3UN7cdCIuYQGlsaaehpY3GjhAJg6Qx5nFDSxujBuEStQoFEZFBkJ2ZwdD8DIbmJ/YVA3VAsYiIdFIoiIhIJ4WCiIh0UiiIiEgnhYKIiHRSKIiISCeFgoiIdFIoiIhIp6S78pqZVQOb3uLLRwE7B7CcRJBq65Rq6wOpt06ptj6QeuvU3fpMdPeSvl6YdKFwOMysoj+Xo0smqbZOqbY+kHrrlGrrA6m3ToezPuo+EhGRTgoFERHplG6hcGPUBcRBqq1Tqq0PpN46pdr6QOqt01ten7TapyAiIr1Lty0FERHphUJBREQ6pU0omNk5ZrbGzNaZ2deirmcgmNlGM3vJzJabWUXU9RwqM7vFzKrMbFXMtBFm9rCZvRbeD4+yxkPVwzpdZ2Zbw89puZm9O8oaD4WZjTezx81stZm9bGafD6cn5efUy/ok82eUZ2bPmdmKcJ2+E06fbGbPhp/Rn8ysXxfFTot9CmaWCawFzgYqgeeBS9z9lUgLO0xmthEod/ekPOnGzN4B1AF3uPsx4bQfArvd/QdheA93969GWeeh6GGdrgPq3P3HUdb2VpjZaGC0u79gZkXAMuD9wJUk4efUy/pcRPJ+RgYUunudmWUD/wI+D3wJuM/d7zKz64EV7v6bvpaXLlsKs4F17r7B3ZuBu4DzI64p7bn7YmB3l8nnA7eHj28n+INNGj2sU9Jy9+3u/kL4uBZYDYwlST+nXtYnaXmgLnyaHd4cmA/cG07v92eULqEwFtgS87ySJP+PEHLgf81smZldHXUxA6TM3bdD8AcMlEZcz0C51sxWht1LSdHV0pWZTQJOAJ4lBT6nLusDSfwZmVmmmS0HqoCHgfXAXndvDZv0+zsvXULBupmWCv1mb3f3E4Fzgc+EXReSeH4DTAXeBmwHfhJtOYfOzIYAfwa+4O41UddzuLpZn6T+jNy9zd3fBowj6BmZ2V2z/iwrXUKhEhgf83wcsC2iWgaMu28L76uA+wn+MyS7HWG/b0f/b1XE9Rw2d98R/tG2AzeRZJ9T2E/9Z+AP7n5fODlpP6fu1ifZP6MO7r4XeAI4BRhmZlnhrH5/56VLKDwPTAv3xucAFwOLIq7psJhZYbijDDMrBN4JrOr9VUlhEXBF+PgK4K8R1jIgOr48QxeQRJ9TuBPzZmC1u/93zKyk/Jx6Wp8k/4xKzGxY+DgfWECwr+Rx4INhs35/Rmlx9BFAeIjZz4BM4BZ3/37EJR0WM5tCsHUAkAX8MdnWyczuBM4kGOZ3B/Bt4C/A3cAEYDPwIXdPmh23PazTmQTdEg5sBK7p6I9PdGZ2GvAU8BLQHk7+d4J++KT7nHpZn0tI3s/oOIIdyZkEP/Tvdvfvht8RdwEjgBeBj7p7U5/LS5dQEBGRvqVL95GIiPSDQkFERDopFEREpJNCQUREOikURESkk0JBEoaZPRPeTzKzjwzwsv+9u/eKFzN7v5l9K07L/ve+Wx3yMo81s9sGermSfHRIqiQcMzsT+Iq7v/cQXpPp7m29zK9z9yEDUV8/63kGOO9wR7Dtbr3itS5m9gjwcXffPNDLluShLQVJGGbWMdLjD4DTw3HtvxgO9vUjM3s+HLDsmrD9meHY+H8kOBkJM/tLOEDgyx2DBJrZD4D8cHl/iH0vC/zIzFZZcG2KD8cs+wkzu9fMXjWzP4Rnw2JmPzCzV8Ja3jTUspkdBTR1BIKZ3WZm15vZU2a21szeG07v93rFLLu7dfmoBePpLzezGywYKh4zqzOz71swzv5SMysLp38oXN8VZrY4ZvEPEJztL+nM3XXTLSFuBOPZQ3AG8IMx068Gvhk+zgUqgMlhu/3A5Ji2I8L7fIKhCkbGLrub97qQYFTJTKCM4Ozc0eGy9xGMGZMBLAFOIzg7dA0HtrKHdbMeHwN+EvP8NuCf4XKmEYzFlXco69Vd7eHjmQRf5tnh818Dl4ePHXhf+PiHMe/1EjC2a/3A24EHov5/oFu0t47BkkQS2TuB48ysYxyXoQRfrs3Ac+7+ekzbz5nZBeHj8WG7Xb0s+zTgTg+6aHaY2ZPAyUBNuOxKgHBY4knAUqAR+K2Z/Q14sJtljgaqu0y724PB1l4zsw3AjENcr56cBZwEPB9uyORzYHC65pj6lhFcZArgaeA2M7sbuO/AoqgCxvTjPSWFKRQkGRjwWXd/6KCJwb6H/V2eLwDmunu9mT1B8Iu8r2X3JHacmDYgy91bzWw2wZfxxcC1BBczidVA8AUfq+vOO6ef69UHA2539693M6/F3Tvet43w793dF5rZHOA9wHIze5u77yL4t2ro5/tKitI+BUlEtUBRzPOHgE+FQx5jZkeFI8N2NRTYEwbCDILhgzu0dLy+i8XAh8P+/RLgHcBzPRVmwTj8Q93978AXCAZR62o1cGSXaR8yswwzmwpMIeiC6u96dRW7Lo8CHzSz0nAZI8xsYm8vNrOp7v6su38L2MmBYeWPIolGB5X40JaCJKKVQKuZrSDoj/85QdfNC+HO3mq6v7TgP4GFZraS4Et3acy8G4GVZvaCu18aM/1+YC6wguDX+7+5+xthqHSnCPirmeUR/Er/YjdtFgM/MTOL+aW+BniSYL/FQndvNLPf9nO9ujpoXczsmwRX4MsAWoDPAJt6ef2PzGxaWP+j4boDzAP+1o/3lxSmQ1JF4sDMfk6w0/aR8Pj/B9393j5eFhkzyyUIrdP8wCUcJQ2p+0gkPv4vUBB1EYdgAvA1BYJoS0FERDppS0FERDopFEREpJNCQUREOikURESkk0JBREQ6/X/hlqMiTXDKgQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.squeeze(costs))\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per tens)')\n",
    "plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the predictibiliy of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL, caches = forward_L(x_test, parameters, activation = \"sigmoid\")   # Input test set to get the prediction output AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = (np.round(AL)-y_test).T        # Get the error matrix by subtracting the rounded AL by y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of prediction error is: 94\n",
      "Accuracy of model is: 0.8825000000000001\n"
     ]
    }
   ],
   "source": [
    "er_count = 0\n",
    "for i in range(len(error)):\n",
    "    if error[i][1] != 0.0:\n",
    "        er_count += 1\n",
    "print(\"Number of prediction error is:\", er_count)\n",
    "print(\"Accuracy of model is:\", 1.0 - float(er_count)/float(len(error)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorFlow we need to create variables for the parameters and placeholders for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,shape=(None, N),name='X')             # None takes care of number of datas\n",
    "Y = tf.placeholder(tf.float32,shape=(None, 2),name='Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "W1 = tf.get_variable(\"W1\", [N,100] )\n",
    "W2 = tf.get_variable(\"W2\", [100,2] )\n",
    "b1 = tf.get_variable(\"b1\", [1,100] )\n",
    "b2 = tf.get_variable(\"b2\", [1,2] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z1 = tf.add(tf.matmul(X, W1),b1)\n",
    "A1 = tf.nn.relu(Z1)\n",
    "Z2 = tf.add(tf.matmul(A1, W2),b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-35-a39b2cea3221>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z2, labels = Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training lgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.005).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-07a100d7b524>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "x_train = x_train.T\n",
    "x_test = x_test.T\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = [] \n",
    "num_epochs = 2000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(num_epochs):\n",
    "        _ , temp_cost = sess.run([optimizer, cost], feed_dict={X: x_train, Y: y_train})\n",
    "          \n",
    "        if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, temp_cost))\n",
    "        if print_cost == True and epoch % 20 == 0:\n",
    "                costs.append(temp_cost)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
